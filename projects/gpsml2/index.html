<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> GPS and ML to detect Earthquakes in Real Time | Tim Dittmann </title> <meta name="author" content="Tim Dittmann"> <meta name="description" content="Part II. Data Augmentation for Deep Learning"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://timdittmann.github.io/projects/gpsml2/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Tim</span> Dittmann </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">GPS and ML to detect Earthquakes in Real Time</h1> <p class="post-description">Part II. Data Augmentation for Deep Learning</p> </header> <article> <blockquote> <p>This is a two part post. This second post addresses challenges we faced in <a href="https://timdittmann.github.io/projects/gpsml1/">part I</a> operating in a data-limited regime.</p> </blockquote> <p>For this project:</p> <ol> <li><a href="#motivation">Motivation</a></li> <li><a href="#data-augmentation-generating-psuedo-synthetic-timeseries">Augmentation</a></li> <li><a href="#more-data-for-deeper-learning">Deep-Learning</a></li> </ol> <hr> <h2 id="motivation">Motivation</h2> <p>Two facts that make data-driven GPS seismology challenging:</p> <ol> <li>Large earthquakes are <a href="https://www.iris.edu/hq/inclass/fact-sheet/how_often_do_earthquakes_occur" rel="external nofollow noopener" target="_blank">relatively infrequent</a> (fortunately!)</li> <li>GPS, the oldest modern positioning satellite constellation, was only “fully” operational (24 satellites) <a href="https://www.nasa.gov/general/global-positioning-system-history/" rel="external nofollow noopener" target="_blank">in 1993</a>.</li> </ol> <p>Given that archiving higher sample rates required to capture earthquake ground motions began ~decade later, and we have a relatively limited dataset of observed events with GNSS.</p> <p>One strategy for addressing this limited data is <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1002/2016JB013314" rel="external nofollow noopener" target="_blank">synthesizing waveforms</a>. We take inspiration from <a href="https://doi.org/10.1029/2021JB022703" rel="external nofollow noopener" target="_blank">Lin et al.</a> using DL models to not only rapidly characterize seismic events but also shed insight into the evolution of large earthquakes.</p> <p>Another strategy is to start with actual clean samples of occurrences and then augment them with the complexity of real-world noise and data variability. For this we found particular inspiration from <a href="https://www.science.org/doi/10.1126/sciadv.aau6792" rel="external nofollow noopener" target="_blank">Hoffman, et al. (2019)</a> strategy for crumpling of paper. (<a href="https://www.nytimes.com/2018/11/26/science/crumple-paper-math.html" rel="external nofollow noopener" target="_blank">Crumpling</a> is a fun topology deep-dive!)</p> <blockquote> <p>An alternative strategy is to consider a reference system free from data limitations alongside the target system, with the idea that similarities between the target and reference systems allow a machine learning model of one to inform that of the other.</p> </blockquote> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="https://www.science.org/cms/10.1126/sciadv.aau6792/asset/5be06f5f-d604-471c-8ae5-41c47a02f56c/assets/graphic/aau6792-f1-480.webp 480w,https://www.science.org/cms/10.1126/sciadv.aau6792/asset/5be06f5f-d604-471c-8ae5-41c47a02f56c/assets/graphic/aau6792-f1-800.webp 800w,https://www.science.org/cms/10.1126/sciadv.aau6792/asset/5be06f5f-d604-471c-8ae5-41c47a02f56c/assets/graphic/aau6792-f1-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="https://www.science.org/cms/10.1126/sciadv.aau6792/asset/5be06f5f-d604-471c-8ae5-41c47a02f56c/assets/graphic/aau6792-f1.jpeg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> What does crumpled paper have to do with earthquakes? </div> <hr> <h2 id="data-augmentation-generating-psuedo-synthetic-timeseries">Data augmentation generating psuedo synthetic timeseries</h2> <p>We generated a pseudo synthetic training catalog, much larger than the existing observed catalog (see image below) as follows:</p> <ul> <li> <strong>real signals:</strong> we query a <a href="https://peer.berkeley.edu/research/nga-west-2" rel="external nofollow noopener" target="_blank">database</a> of “noise-free” strong motion waveforms</li> <li> <strong>synthetic noise:</strong> we characterize the frequency distribution of real noise, from which we can sample to generate realistic synthetic noise.</li> </ul> <p>This database is not <em>free from data limitations</em> in the paper crumbling approach, but does offer a much larger (~60x) set with clean labels from which to train (figure below).</p> <hr> <blockquote> <p><strong>real earthquake</strong> signals + <strong>synthetic GPS</strong> noise = <strong>psuedosynthetic GPS earthquake</strong> timeseries</p> </blockquote> <hr> <ul> <li> <a href="https://seismica.library.mcgill.ca/article/view/978" rel="external nofollow noopener" target="_blank">Open-access manuscript. </a><a class="citation" href="#Dittmann_Morton_Crowell_Melgar_DeGrande_Mencin_2023">(Dittmann et al., 2023)</a> </li> <li><a href="https://zenodo.org/records/7909327" rel="external nofollow noopener" target="_blank">Open Data Catalog.</a></li> <li><a href="https://github.com/timdittmann/psuedosynth_gnss_velocities" rel="external nofollow noopener" target="_blank">Code repo.</a></li> </ul> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project2/synth_ngaw_gnss_distrib-480.webp 480w,/assets/img/project2/synth_ngaw_gnss_distrib-800.webp 800w,/assets/img/project2/synth_ngaw_gnss_distrib-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project2/synth_ngaw_gnss_distrib.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project2/ambientnoise_H-480.webp 480w,/assets/img/project2/ambientnoise_H-800.webp 800w,/assets/img/project2/ambientnoise_H-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project2/ambientnoise_H.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> (L) (a) is a histogram comparing the GNSS catalog with the strong motion database (“NGAW2”). The scatter plot in (b) are the individual event magnitudes as a function of time, and the secondary axis line plot is the cumulative station count over time observing the events. (R) GNSS 5Hz velocity probabilistic power spectral densities for horizontal components of motion. This characterization of stochastic noise in the frequency domain is used to generate representative synthetic noise. </div> <hr> <h2 id="more-data-for-deeper-learning">More data for deeper learning</h2> <p>Questions:</p> <ol> <li> <strong>Are these psuedosynthetics representative of real-world data?</strong>. <ul> <li>We trained one model only with these synthetics, and another with the <a href="https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2022JB024854" rel="external nofollow noopener" target="_blank">observed data</a>. On a held-aside unseen testing dataset, the synthetic-data-driven model outpeformed the real-data-driven case. <a class="citation" href="#Dittmann_Morton_Crowell_Melgar_DeGrande_Mencin_2023">(Dittmann et al., 2023)</a> </li> </ul> </li> <li> <strong>What questions can we ask given increased data volume and veracity?</strong> <ul> <li>We experiment with deeper learning applications made possible by the volume and labels of this data catalog.</li> </ul> </li> </ol> <h3 id="experiment-denoising-timeseries-with-deep-learning">Experiment: Denoising timeseries with deep learning</h3> <ul> <li> <strong>Objective:</strong> In order to increase the signal to noise ratio (SNR) of relatively weak signals embedded in complex noise, we train a U-net convolutional network architecture used for image processing on <strong><em>denoising</em></strong> time windows of highrate GNSS velocity timeseries. Unlike traditional fixed bandwidth frequency filtering, the neural network learns a sparse representation mask of time-frequency domain features to separate complex, time-variant noise signatures from a range of signal inputs.</li> <li> <strong>Data:</strong> We train the model using the previously mentioned catalog of synthetic 5Hz TDCP horizontal waveforms. After splitting and windowing, the training set consists of ~75k samples.</li> <li> <strong>Features:</strong> Following the strategy of <a href="https://arxiv.org/abs/1811.02695" rel="external nofollow noopener" target="_blank">Zhu et al. (2019)</a> and <a href="https://seismica.library.mcgill.ca/article/view/240" rel="external nofollow noopener" target="_blank">Thomas et al. (2023)</a>, these incoming waveforms, Y (t) are represented as the superposition of signal S(t) and noise N(t), and their short-time fourier transforms (STFT), can be represented as:</li> </ul> <p>\begin{equation} Y(t,f) = S(t,f) + N(t,f) \end{equation}</p> <p>Our model input features are the STFT \(Y(t,f)\) from 90 second, non-overlapping windows extracted from the horizontal components of motion.</p> <p>The model target is a signal mask, \(M_s(t,f)\):</p> <p>\begin{equation} M_s(t,f) = \frac{1}{1+\frac{\lvert N(t,f) \rvert }{\lvert S(t,f) \rvert}} \end{equation}</p> <p>where \(N(t,f)\) and \(S(t,f)\) are the noise and signal STFT, respectively.</p> <ul> <li> <p><strong>ML Architecture:</strong> The convolutional neural network (CNN) employed is a <a href="https://arxiv.org/abs/1505.04597" rel="external nofollow noopener" target="_blank">U-Net</a> architecture, originally developed for biomedical image-segmentation. We train the UNET using the Adam optimizer with a learning rate of 0.001, determined through hyperparamter optimization tuning. The model training is optimized using the mean square estimator (MSE) loss function. We train the model using the open source deep learning software <a href="https://github.com/tensorflow/tensorflow" rel="external nofollow noopener" target="_blank">TensorFlow</a>, with a batch size of 128 and 50 epochs, determined experimentally.</p> </li> <li> <p><strong>Manuscript:</strong> <a class="citation" href="#Dittmann2024">(Dittmann et al., 2024)</a></p> </li> <li> <p><strong>Results:</strong></p> </li> </ul> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project2/denoise_flow.drawio-480.webp 480w,/assets/img/project2/denoise_flow.drawio-800.webp 800w,/assets/img/project2/denoise_flow.drawio-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project2/denoise_flow.drawio.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Flow chart for denoising GNSS velocities, where a) is a ’raw’ single horizontal component 90 second window of 5HZ TDCP velocities. b) is the real and imaginary components of the Short Time Fourier Transform of this incoming (signal+noise) timeseries (eq. 1) that are the input to the UNET model, c) . This model outputs a frequency mask, d), (eq. 2) which is then applied to the original inputs, b) to generate a denoised STFT, e). Lastly, the inverse transform outputs a denoised time series, f). </div> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project2/denoise_ex4873-480.webp 480w,/assets/img/project2/denoise_ex4873-800.webp 800w,/assets/img/project2/denoise_ex4873-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project2/denoise_ex4873.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/project2/snr_marg_peaksig-480.webp 480w,/assets/img/project2/snr_marg_peaksig-800.webp 800w,/assets/img/project2/snr_marg_peaksig-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/project2/snr_marg_peaksig.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="example image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> (L) A denoised analysis of a horizontal strong motion waveform. The left panels (a) are the psuedosynthetic waveforms of stochastic GNSS noise and the true strong motion signal, shown in the middle panels (b). The right panels are the denoised panel (a). The top panels are time series, the bottom panels are the STFT for the window. (R) Distribution of increase in SNR from denoising as a function of peak signal amplitude. The scatter is shaded by density of samples, and the marginal distributions for signal amplitude and SNR increase are visible on the top and right panels, respectively. </div> <h2 id="whats-next">What’s next?</h2> <h3 id="method">Method</h3> <ul> <li>evaluate denoising of existing <a href="https://zenodo.org/records/7909327" rel="external nofollow noopener" target="_blank">observed waveform catalog</a>.</li> <li>experiment with alternative feature/target and DL architecture strategies</li> <li>investigate integration with <a href="https://timdittmann.github.io/projects/gpsml1/#model-training-highlights">classification</a> </li> </ul> <h3 id="product">Product</h3> <ul> <li>Integrate this DL into <a href="https://timdittmann.github.io/projects/gpsml1/#real-time-inference-experiment">real-time stream processing</a> of TDCP velocity streams for boosting SNR of GNSS seismology.</li> </ul> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Dittmann2024" class="col-sm-8"> <div class="title">Denoising GNSS Velocities for Earthquake Ground Motions with Deep Learning</div> <div class="author"> Tim Dittmann , Jade Morton , and David Mencin </div> <div class="periodical"> <em>In The International Technical Meeting of the The Institute of Navigation</em> , Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/ION_Conference_Paper_dittmann2024.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Dittmann2024</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ITM 2024}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Denoising GNSS Velocities for Earthquake Ground Motions with Deep Learning}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2330-3646}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://dx.doi.org/10.33012/2024.19523}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.33012/2024.19523}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The International Technical Meeting of the The Institute of Navigation}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Institute of Navigation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dittmann, Tim and Morton, Jade and Mencin, David}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">collection</span> <span class="p">=</span> <span class="s">{ITM 2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 abbr"> </div> <div id="Dittmann_Morton_Crowell_Melgar_DeGrande_Mencin_2023" class="col-sm-8"> <div class="title">Characterizing High Rate GNSS Velocity Noise for Synthesizing a GNSS Strong Motion Learning Catalog</div> <div class="author"> Timothy Dittmann , Y. Jade Morton , Brendan Crowell , and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Diego Melgar, Jensen DeGrande, David Mencin' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>Seismica</em>, Oct 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Dittmann_Morton_Crowell_Melgar_DeGrande_Mencin_2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Characterizing High Rate GNSS Velocity Noise for Synthesizing a GNSS Strong Motion Learning Catalog}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://seismica.library.mcgill.ca/article/view/978}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.26443/seismica.v2i2.978}</span><span class="p">,</span>
  <span class="na">abstractnote</span> <span class="p">=</span> <span class="s">{&amp;amp;lt;p&amp;amp;gt;Data-driven approaches to identify geophysical signals have proven beneficial in high dimensional environments where model-driven methods fall short. GNSS offers a source of unsaturated ground motion observations that are the data currency of ground motion forecasting and rapid seismic hazard assessment and alerting. However, these GNSS-sourced signals are superposed onto hardware-, location- and time-dependent noise signatures influenced by the Earth’s atmosphere, low-cost or spaceborne oscillators, and complex radio frequency environments. Eschewing heuristic or physics based models for a data-driven approach in this context is a step forward in autonomous signal discrimination. However, the performance of a data-driven approach depends upon substantial representative samples with accurate classifications, and more complex algorithm architectures for deeper scientific insights compound this need. The existing catalogs of high-rate (&amp;amp;lt;span class=&amp;amp;quot;ILfuVd&amp;amp;quot; lang=&amp;amp;quot;en&amp;amp;quot;&amp;amp;gt;&amp;amp;lt;span class=&amp;amp;quot;hgKElc&amp;amp;quot;&amp;amp;gt;≥&amp;amp;lt;/span&amp;amp;gt;&amp;amp;lt;/span&amp;amp;gt;1Hz) GNSS ground motions are relatively limited. In this work, we model and evaluate the probabilistic noise of GNSS velocity measurements over a hemispheric network. We generate stochastic noise time series to augment transferred low-noise strong motion signals from within 70 kilometers of strong events (&amp;amp;lt;span class=&amp;amp;quot;ILfuVd&amp;amp;quot; lang=&amp;amp;quot;en&amp;amp;quot;&amp;amp;gt;&amp;amp;lt;span class=&amp;amp;quot;hgKElc&amp;amp;quot;&amp;amp;gt;≥&amp;amp;lt;/span&amp;amp;gt;&amp;amp;lt;/span&amp;amp;gt; M&amp;amp;lt;sub&amp;amp;gt;W&amp;amp;lt;/sub&amp;amp;gt; 5.0) from an existing inertial catalog. We leverage known signal and noise information to assess feature extraction strategies and quantify augmentation benefits. We find a classifier model trained on this expanded pseudo-synthetic catalog improves generalization compared to a model trained solely on a real-GNSS velocity catalog, and offers a framework for future enhanced data driven approaches.&amp;amp;lt;/p&amp;amp;gt;}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Seismica}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dittmann, Timothy and Morton, Y. Jade and Crowell, Brendan and Melgar, Diego and DeGrande, Jensen and Mencin, David}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Tim Dittmann. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>